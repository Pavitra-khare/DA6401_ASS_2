{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 11368356,
          "sourceType": "datasetVersion",
          "datasetId": 7116343
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "DA6401_ASS_2A_SWEEPs",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavitra-khare/DA6401_ASS_2/blob/main/DA6401_ASS_2A_SWEEPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:05.816007Z",
          "iopub.execute_input": "2025-04-11T18:44:05.816314Z",
          "iopub.status.idle": "2025-04-11T18:44:08.844846Z",
          "shell.execute_reply.started": "2025-04-11T18:44:05.816279Z",
          "shell.execute_reply": "2025-04-11T18:44:08.84387Z"
        },
        "id": "NgrzpbpiZhip"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key='b32b3fa2b8b3c86c7a8a232ec7d97bf3eda57182')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:08.846478Z",
          "iopub.execute_input": "2025-04-11T18:44:08.846784Z",
          "iopub.status.idle": "2025-04-11T18:44:15.904979Z",
          "shell.execute_reply.started": "2025-04-11T18:44:08.84676Z",
          "shell.execute_reply": "2025-04-11T18:44:15.904256Z"
        },
        "id": "7oYWLvTjZhip"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wandb\n",
        "from types import SimpleNamespace\n",
        "import random\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:15.905729Z",
          "iopub.execute_input": "2025-04-11T18:44:15.90606Z",
          "iopub.status.idle": "2025-04-11T18:44:22.847157Z",
          "shell.execute_reply.started": "2025-04-11T18:44:15.906042Z",
          "shell.execute_reply": "2025-04-11T18:44:22.846488Z"
        },
        "id": "MVOXl70YZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:22.847889Z",
          "iopub.execute_input": "2025-04-11T18:44:22.848232Z",
          "iopub.status.idle": "2025-04-11T18:44:22.906863Z",
          "shell.execute_reply.started": "2025-04-11T18:44:22.848215Z",
          "shell.execute_reply": "2025-04-11T18:44:22.905968Z"
        },
        "id": "u_1QfDGfZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def img_size(img_w, filter_size, padding, stride):\n",
        "    return (1 / 2) * (1 + (img_w - filter_size + (2 * padding)) / stride)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:22.909074Z",
          "iopub.execute_input": "2025-04-11T18:44:22.909296Z",
          "iopub.status.idle": "2025-04-11T18:44:22.9252Z",
          "shell.execute_reply.started": "2025-04-11T18:44:22.909278Z",
          "shell.execute_reply": "2025-04-11T18:44:22.924501Z"
        },
        "id": "JnXxzA5iZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_filters=[32, 64, 128, 256, 512], filter_size=[3, 3, 5, 5, 7],\n",
        "                 activation=nn.ReLU(), stride=1, padding=1, pool_size=(2, 2), fc_size=512, num_classes=10,\n",
        "                 dropout=0, batch_norm = 'Yes'):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.channels = in_channels\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.activation = activation\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pool_size = pool_size\n",
        "        self.fc_size = fc_size\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout = dropout\n",
        "        self.batch_norm = batch_norm\n",
        "\n",
        "        # Define convolutional layers\n",
        "        self.conv1 = nn.Conv2d(self.channels, self.num_filters[0], self.filter_size[0], stride=self.stride, padding=self.padding)\n",
        "        self.dropout1 = nn.Dropout2d(self.dropout)\n",
        "        self.conv2 = nn.Conv2d(self.num_filters[0], self.num_filters[1], self.filter_size[1], stride=self.stride,padding=self.padding)\n",
        "        self.dropout2 = nn.Dropout2d(self.dropout)\n",
        "        self.conv3 = nn.Conv2d(self.num_filters[1], self.num_filters[2], self.filter_size[2], stride=self.stride,padding=self.padding)\n",
        "        self.dropout3 = nn.Dropout2d(self.dropout)\n",
        "        self.conv4 = nn.Conv2d(self.num_filters[2], self.num_filters[3], self.filter_size[3], stride=self.stride,padding=self.padding)\n",
        "        self.dropout4 = nn.Dropout2d(self.dropout)\n",
        "        self.conv5 = nn.Conv2d(self.num_filters[3], self.num_filters[4], self.filter_size[4], stride=self.stride,padding=self.padding)\n",
        "        self.dropout5 = nn.Dropout2d(self.dropout)\n",
        "\n",
        "        # Define batch normalization layers\n",
        "        self.batchnorm1 = nn.BatchNorm2d(self.num_filters[0])\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.num_filters[1])\n",
        "        self.batchnorm3 = nn.BatchNorm2d(self.num_filters[2])\n",
        "        self.batchnorm4 = nn.BatchNorm2d(self.num_filters[3])\n",
        "        self.batchnorm5 = nn.BatchNorm2d(self.num_filters[4])\n",
        "\n",
        "        # Define activation function\n",
        "        self.activation = activation\n",
        "\n",
        "        # Define max pooling layers\n",
        "        self.pool = nn.MaxPool2d(self.pool_size, stride=2)  # for maxpool default stride is 2 and padding is 0\n",
        "\n",
        "\n",
        "        # Calculating image width and height after each layer\n",
        "        nxt_size1 = img_size(224, self.filter_size[0], self.padding, self.stride)\n",
        "        nxt_size2 = img_size(nxt_size1, self.filter_size[1], self.padding, self.stride)\n",
        "        nxt_size3 = img_size(nxt_size2, self.filter_size[2], self.padding, self.stride)\n",
        "        nxt_size4 = img_size(nxt_size3, self.filter_size[3], self.padding, self.stride)\n",
        "        nxt_size5 = img_size(nxt_size4, self.filter_size[4], self.padding, self.stride)\n",
        "        nxt_size5 = int(nxt_size5)\n",
        "\n",
        "        # Define dropout layer\n",
        "        self.dropout_layer = nn.Dropout1d(self.dropout)\n",
        "\n",
        "        # Define fully connected layer\n",
        "        self.fc = nn.Linear(self.num_filters[4] * (nxt_size5 ** 2), self.fc_size)\n",
        "        self.fc_bn = nn.BatchNorm1d(self.fc_size)  # Batch normalization for fully connected layer\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(self.fc_size, self.num_classes)\n",
        "\n",
        "    # Forward propagation function\n",
        "    def forward(self, x):\n",
        "        # 1st conv layer\n",
        "        x = self.conv1(x)\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.batchnorm1(x)\n",
        "        else:\n",
        "            x = x\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "\n",
        "        # 2nd conv layer\n",
        "        x = self.conv2(x)\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.batchnorm2(x)\n",
        "        else:\n",
        "            x = x\n",
        "        # x = self.batchnorm2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "\n",
        "        # 3rd conv layer\n",
        "        x = self.conv3(x)\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.batchnorm3(x)\n",
        "        else:\n",
        "            x = x\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "\n",
        "        # 4th conv layer\n",
        "        x = self.conv4(x)\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.batchnorm4(x)\n",
        "        else:\n",
        "            x = x\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        # 5th conv layer\n",
        "        x = self.conv5(x)\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.batchnorm5(x)\n",
        "        else:\n",
        "            x = x\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout5(x)\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc(x)\n",
        "        # Batch normalization before activation\n",
        "        if self.batch_norm == 'Yes':\n",
        "            x = self.fc_bn(x)\n",
        "        else:\n",
        "            x = x\n",
        "        # x = self.fc_bn(x)\n",
        "        x = self.activation(x)\n",
        "        # Apply dropout\n",
        "        x = self.dropout_layer(x)\n",
        "        # Output layer\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Making object of the ConvNet class\n",
        "model = ConvNet().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:22.925956Z",
          "iopub.execute_input": "2025-04-11T18:44:22.92624Z",
          "iopub.status.idle": "2025-04-11T18:44:23.453471Z",
          "shell.execute_reply.started": "2025-04-11T18:44:22.926211Z",
          "shell.execute_reply": "2025-04-11T18:44:23.452769Z"
        },
        "id": "v0Xf4p9oZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " # Function to test the model\n",
        "def test_on_valid_data(model, test_data):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_val_label = 0\n",
        "    total_val_label = 0\n",
        "    with torch.no_grad():  # Turn off gradient calculation for validation\n",
        "        for img, label in test_data:\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            output = model(img)\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct_val_label += (pred == label).sum().item()\n",
        "            total_val_label += label.size(0)\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    valid_accuracy = 100 * correct_val_label / total_val_label\n",
        "    return valid_accuracy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.454187Z",
          "iopub.execute_input": "2025-04-11T18:44:23.454454Z",
          "iopub.status.idle": "2025-04-11T18:44:23.459479Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.454435Z",
          "shell.execute_reply": "2025-04-11T18:44:23.458692Z"
        },
        "id": "lI6wossvZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train_val(model, train_data, val_data, epochs):\n",
        "    best_val_acc = 0\n",
        "    patience = 2\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model, avg_loss, train_accuracy = train_on_train_data(model, train_data)\n",
        "        val_accuracy = test_on_valid_data(model, val_data)\n",
        "\n",
        "        wandb.log({\n",
        "            'Train loss': avg_loss,\n",
        "            'Train accuracy': train_accuracy,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_accuracy > best_val_acc:\n",
        "            best_val_acc = val_accuracy\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.460229Z",
          "iopub.execute_input": "2025-04-11T18:44:23.460738Z",
          "iopub.status.idle": "2025-04-11T18:44:23.477239Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.460716Z",
          "shell.execute_reply": "2025-04-11T18:44:23.476601Z"
        },
        "id": "rW6HY1qqZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model on train data\n",
        "def train_on_train_data(model, train_data):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()  # Set the model to training mode\n",
        "    training_loss = 0.0\n",
        "    correct_train_label = 0\n",
        "    total_train = 0\n",
        "    # Training loop\n",
        "    for inputs, labels in train_data:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct_train_label += (pred == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    # Calculate training loss and accuracy\n",
        "    avg_loss = training_loss / len(train_data)\n",
        "    train_accuracy = 100 * correct_train_label / total_train\n",
        "    return model, avg_loss, train_accuracy\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.478138Z",
          "iopub.execute_input": "2025-04-11T18:44:23.478604Z",
          "iopub.status.idle": "2025-04-11T18:44:23.489256Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.478577Z",
          "shell.execute_reply": "2025-04-11T18:44:23.488729Z"
        },
        "id": "Q-5WwQdTZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data loader function\n",
        "\n",
        "train_data_dir = '/kaggle/input/my-dataset/inaturalist_12K/train'\n",
        "\n",
        "def data_load(train_data_dir,data_augumentation):\n",
        "\n",
        "    # Define variables to transeform the images to tensor and for data augumentation\n",
        "    resize = transforms.Resize((224, 224))\n",
        "    convert_to_tensor = transforms.ToTensor()\n",
        "    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    resize_crop = transforms.RandomResizedCrop(224)\n",
        "    h_flip = transforms.RandomHorizontalFlip()\n",
        "    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "    rand_rotation = transforms.RandomRotation(20)\n",
        "\n",
        "    # Data augumentation\n",
        "    if data_augumentation == 'Yes':\n",
        "        transform_img = transforms.Compose([resize_crop,h_flip,color_jitter, rand_rotation, convert_to_tensor,normalize]) # Data transformations\n",
        "\n",
        "    else:\n",
        "        transform_img = transforms.Compose([resize,convert_to_tensor, normalize ])  # Data transformations\n",
        "\n",
        "    # Load the dataset using ImageFolder and apply transformations\n",
        "    training_data = ImageFolder(root=train_data_dir, transform=transform_img)\n",
        "    # Splitting train dataset into training and validation indices\n",
        "    train_index, val_index = train_test_split(list(range(len(training_data))), test_size=0.2, random_state=42)\n",
        "    # Create DataLoader instances for training and validation sets\n",
        "    random_train_sample = SubsetRandomSampler(train_index)\n",
        "    train_data = DataLoader(\n",
        "    training_data,\n",
        "    batch_size=32,\n",
        "    sampler=random_train_sample,\n",
        "    num_workers=4,  # Add workers for parallel loading\n",
        "    pin_memory=True  # Faster data transfer to GPU\n",
        "    )\n",
        "\n",
        "    random_val_sample = SubsetRandomSampler(val_index)\n",
        "    validation_data = DataLoader(\n",
        "    training_data,\n",
        "    batch_size=32,\n",
        "    sampler=random_val_sample,\n",
        "    num_workers=4,  # Add workers for parallel loading\n",
        "    pin_memory=True  # Faster data transfer to GPU\n",
        "    )\n",
        "    return train_data, validation_data\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.490087Z",
          "iopub.execute_input": "2025-04-11T18:44:23.490401Z",
          "iopub.status.idle": "2025-04-11T18:44:23.506285Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.490378Z",
          "shell.execute_reply": "2025-04-11T18:44:23.50559Z"
        },
        "id": "hsUkVhXkZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data loader function\n",
        "test_data_dir = '/kaggle/input/my-dataset/inaturalist_12K/val'\n",
        "\n",
        "def test_data_load(test_data_dir,data_augumentation):\n",
        "    # Define variables to transeform the images to tensor and for data augumentation\n",
        "    resize = transforms.Resize((224, 224))\n",
        "    convert_to_tensor = transforms.ToTensor()\n",
        "    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    resize_crop = transforms.RandomResizedCrop(224)\n",
        "    h_flip = transforms.RandomHorizontalFlip()\n",
        "    color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "    rand_rotation = transforms.RandomRotation(20)\n",
        "\n",
        "    # Data augumentation\n",
        "    if data_augumentation == 'Yes':\n",
        "        transform_img = transforms.Compose([resize_crop,h_flip,color_jitter, rand_rotation, convert_to_tensor,normalize]) # Data transformations\n",
        "\n",
        "    else:\n",
        "        transform_img = transforms.Compose([resize,convert_to_tensor, normalize ])  # Data transformations\n",
        "\n",
        "    # Load the dataset using ImageFolder and apply transformations\n",
        "    test_data = ImageFolder(root=test_data_dir, transform=transform_img)\n",
        "    # Apply DataLoader to load the test data with batch sizes\n",
        "    testData = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=32,\n",
        "    num_workers=4,  # Add workers for parallel loading\n",
        "    pin_memory=True  # Faster data transfer to GPU\n",
        "    )\n",
        "\n",
        "    return testData"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.507034Z",
          "iopub.execute_input": "2025-04-11T18:44:23.507325Z",
          "iopub.status.idle": "2025-04-11T18:44:23.521618Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.507306Z",
          "shell.execute_reply": "2025-04-11T18:44:23.520984Z"
        },
        "id": "Pr4A0MvoZhiq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'kernel_size':{\n",
        "            'values': [[3,3,3,3,3],[3,5,5,7,7],[3,5,3,5,7],[5,5,5,5,5]]#,[7,7,7,7,7]]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.3, 0.2]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': [ 'relu','mish','silu', 'gelu',]\n",
        "        },\n",
        "        'num_dense':{\n",
        "            'values': [128, 256]\n",
        "        },\n",
        "        'batch_norm':{\n",
        "            'values': ['Yes','No']\n",
        "        },\n",
        "        'filter_org':{\n",
        "            'values': [[128,128,64,64,32],[32,64,128,256,512],[32,32,32,32,32],[32,64,64,128,128]]\n",
        "        },\n",
        "        'data_aug': {\n",
        "            'values': ['No', 'Yes']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config,project=\"DL_ASS2\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:23.522493Z",
          "iopub.execute_input": "2025-04-11T18:44:23.522781Z",
          "iopub.status.idle": "2025-04-11T18:44:24.019034Z",
          "shell.execute_reply.started": "2025-04-11T18:44:23.522756Z",
          "shell.execute_reply": "2025-04-11T18:44:24.018309Z"
        },
        "id": "sNkFfrX_Zhir"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "C3lvveS2Zhir"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    '''\n",
        "    WandB calls main function each time with differnet combination.\n",
        "\n",
        "    We can retrive the same and use the same values for our hypermeters.\n",
        "\n",
        "    '''\n",
        "\n",
        "    with wandb.init() as run:\n",
        "        run_name=\"ks\"+str(wandb.config.kernel_size)+\"ac-\"+(wandb.config.activation)+\"_drop-\"+str(wandb.config.dropout)+\"_daug-\"+str(wandb.config.data_aug)+\"_fs-\"+str(wandb.config.filter_org)+\"_bn-\"+str(wandb.config.batch_norm)+\"_dence-\"+str(wandb.config.num_dense)\n",
        "        wandb.run.name=run_name\n",
        "\n",
        "        if  wandb.config.activation == 'relu':\n",
        "            activ=nn.ReLU()\n",
        "        elif wandb.config.activation == 'gelu':\n",
        "            activ=nn.GELU()\n",
        "        elif wandb.config.activation == 'silu':\n",
        "            activ=nn.SiLU()\n",
        "        elif wandb.config.activation == 'mish':\n",
        "            activ=nn.Mish()\n",
        "\n",
        "        model = ConvNet(in_channels=3, num_filters=wandb.config.filter_org, filter_size=wandb.config.kernel_size, activation=activ, stride=1,\n",
        "                        padding=1, pool_size=(2,2), fc_size=wandb.config.num_dense, num_classes=10,dropout = wandb.config.dropout,batch_norm=wandb.config.batch_norm).to(device)\n",
        "\n",
        "#         data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n",
        "        train_data_dir = '/kaggle/input/my-dataset/inaturalist_12K/train'\n",
        "        train, validation = data_load(train_data_dir,data_augumentation= wandb.config.data_aug)\n",
        "\n",
        "        model_train_val(model, train, validation, epochs = 7)\n",
        "\n",
        "#         model_train(model,train,validation)\n",
        "\n",
        "wandb.agent(\"gvh886k1\", function= main,count= 70) # calls main function for count number of times.\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T18:44:24.019746Z",
          "iopub.execute_input": "2025-04-11T18:44:24.01996Z",
          "execution_failed": "2025-04-11T21:37:50.088Z"
        },
        "id": "wVPf_0GTZhir"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "L-Z2hQqvZhir"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}